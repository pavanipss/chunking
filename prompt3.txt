# ============================================================
# ğŸ¯ GOAL
# ============================================================
You are my enterprise GenAI developer inside Copilot.
Reproduce **Step 3 of the Behavioral Compliance Architecture**:
a Python pipeline that integrates the local Rule Engine (Step 1) +
Gemini reasoning (Step 2) using **Vertex AI Managed SDK** 
with **Application Default Credentials (ADC)** authentication.

# ============================================================
# ğŸ“˜ CONTEXT â€” ARCHITECTURE OVERVIEW
# ============================================================
Input Data Source (chat/email/social text from Excel)
        â”‚
        â–¼
Step 1 â€” Rule Engine (Regex / YAML Bible)
        â”‚
        â–¼
Auto-Labeled (High-Confidence)â€ƒâ€ƒGray-Zone (Unresolved)
        â”‚â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ”‚
        â–¼â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ–¼
Save â†’ Final CSVâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ†’â€ƒStep 2 â€” Gemini Model (LLM reasoning)
                                             â”‚
                                             â–¼
                                 Combined Output â†’ SME Dashboard / Excel

You are now implementing **Step 3 â€“ Vertex AI Managed Gemini Pipeline**
to automate Steps 1 + 2 with enterprise authentication.

# ============================================================
# ğŸ§¾ INPUT SOURCES
# ============================================================
1. **behavior_bible.yaml** â€” YAML rule bible
   Each rule has:
   - id, label, severity, patterns[], explanation
2. **communication_data.xlsx** â€” Excel file
   - Columns: ID, TEXT
   - Each row = one chat/email/social message

# ============================================================
# ğŸ§© TASK
# ============================================================
Generate a full Python script that:
1ï¸âƒ£ Authenticates automatically using ADC (no API key)  
2ï¸âƒ£ Implements a local regex Rule Engine that:
â€ƒâ€ƒâ€¢ Loads rules from behavior_bible.yaml  
â€ƒâ€ƒâ€¢ Matches patterns in TEXT  
â€ƒâ€ƒâ€¢ Returns {label, severity, explanation, policy_recommendation}  
3ï¸âƒ£ Calls **Vertex AI Gemini** for unresolved gray-zone records:  
â€ƒâ€ƒâ€¢ Uses `vertexai.preview.language_models.TextGenerationModel`  
â€ƒâ€ƒâ€¢ Model name = "gemini-1.5-pro" (or gemini-2.0-pro when available)  
â€ƒâ€ƒâ€¢ Temperature = 0.0, max_output_tokens = 1500  
â€ƒâ€ƒâ€¢ Prompt template loaded from behavior_prompts.txt  
â€ƒâ€ƒâ€¢ Replaces `{data_as_json_string}` placeholder with records JSON  
â€ƒâ€ƒâ€¢ Batch size = 40  
4ï¸âƒ£ Parses Gemini JSON output and appends to results  
5ï¸âƒ£ Combines local and Gemini outputs into one DataFrame â†’ return  

# ============================================================
# ğŸ’» REQUIREMENTS
# ============================================================
- Auto-discovery of credentials via ADC (service account or `gcloud auth application-default login`)
- No `api_key` in code
- Imports â†’ `re`, `json`, `asyncio`, `pandas`, `yaml`
- Vertex AI SDK â†’ `google-cloud-aiplatform`, `vertexai`
- Optional â†’ `pydantic-ai` governed wrapper version

# ============================================================
# ğŸ§± EXPECTED CODE STRUCTURE
# ============================================================
```python
import re, json, asyncio, pandas as pd
from vertexai.preview.language_models import TextGenerationModel
from behavior_bible import rules
from schemas import ModelOutput

BATCH_SIZE = 40

def apply_rule_engine(text):
    for rule in rules:
        for pat in rule["patterns"]:
            if re.search(pat, text):
                return {
                    "label": rule["label"],
                    "severity": rule["severity"],
                    "explanation": rule["explanation"],
                    "policy_recommendation": "BLOCK" if rule["severity"]=="HIGH" else "ALLOW"
                }
    return None

async def call_gemini(prompt: str):
    model = TextGenerationModel.from_pretrained("gemini-1.5-pro")
    response = model.predict(prompt, temperature=0.0, max_output_tokens=1500)
    return response.text

async def process_pipeline(df: pd.DataFrame):
    gemini_inputs = []
    results = []

    for _, row in df.iterrows():
        rule_out = apply_rule_engine(row["TEXT"])
        if rule_out:
            results.append({"id": row["ID"], **rule_out})
        else:
            gemini_inputs.append(row)

    print(f"Local rule engine labeled {len(results)} records.")
    print(f"Sending {len(gemini_inputs)} ambiguous records to Gemini...")

    if gemini_inputs:
        template = open("behavior_prompts.txt").read()
        for i in range(0, len(gemini_inputs), BATCH_SIZE):
            batch = gemini_inputs[i:i+BATCH_SIZE]
            records = [{"id": str(r["ID"]), "text": r["TEXT"]} for _, r in batch.iterrows()]
            prompt = template.replace("{data_as_json_string}", json.dumps(records))
            raw = await asyncio.to_thread(call_gemini, prompt)
            try:
                parsed = json.loads(raw)
                results.extend(parsed)
            except Exception as e:
                print("Parse error", e)

    return pd.DataFrame(results)
